apiVersion: batch/v1
kind: Job
metadata:
  name: bert-finetuning-mlflow-demo
  namespace: soperator
spec:
  template:
    spec:
      restartPolicy: Never
      nodeSelector:
        node.kubernetes.io/instance-type: gpu-h100-sxm
      containers:
      - name: finetuning
        image: nvcr.io/nvidia/pytorch:23.10-py3
        command: ["python", "/scripts/finetune_bert_mlflow.py"]
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-tracking:5000"
        resources:
          requests:
            nvidia.com/gpu: "1"
        volumeMounts:
        - name: training-script
          mountPath: /scripts
        - name: mlflow-integration
          mountPath: /mlflow-utils
        - name: model-storage
          mountPath: /model
      volumes:
      - name: training-script
        configMap:
          name: bert-training-mlflow-script
      - name: mlflow-integration
        configMap:
          name: mlflow-integration-scripts
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-storage
